# 凸优化算法

### 梯度

什么是梯度,数学含义,图像上



线性回归

$h_{\theta}=\sum_{j=0}^{n}\theta_{j}x_{j}$

损失函数

$J_{train}(\theta)=\frac{1}{2m}\sum_{i=1}^{m}(h_{\theta}(x^{(i)})-y^{(i)})^{2}$

####批量梯度下降(BGD)



###随机梯度下降(SGD)

### MiniBatch GD

 





每个样本的损失函数

梯度公式

> 参考 https://www.cnblogs.com/maybe2030/p/5089753.html
GBDT；adaBoost ; 

SVM 初步

反向传播推导;adam 优化器的作用

pytorch 入门

CNN 起码是第二种模型方法看懂，问什么要那么做，原因是什么

刷剑指offer

hash 相关的用法

美团，腾讯，今日头条，阿里简历

### 2018.3.19

1. 复习word2vec，神经网络基础知识，把CNN 那个模型和代码看明白,CNN 激活函数为什么选择relu，CNN max pooling 为什么能解决边长问题，CNN 中padding
   - pooling 可以把取每个filter 的最大值，不管filter 中维数是多少
2. 再了解一些集成学习的方法，GBDT，adBoost
3. 吃饭回来时间，填写腾讯网上信息
4. 核心，复习剪枝offer ，和基础题，像排序，二分查找，字符串(字符串复制)

### 2018.3.18 

1. mergesort
2. 优化方法 adam，rsp
3. CNN 论文，模型总结，搞清楚，怎么做，为什么

### 2018.3.17

1. 模型选择方法(面试回馈)，看了李航，加入正则项，优先选择比较简单的模型
2. mergesort 

### 2018.3.16

1. 复习HMM，word2vec （带着问题去思考）
2. 完善mooc 分析的项目，整个过一遍流程，不去做CNN
3. 学习新的SVM 知识
4. 找个练手的公司投简历，积累经验

### 2018.3.15

1. 复习HMM, word2vec( word2vec 与 glove 的区别)
2. 核心，把文本理解那个实验流程过一遍，特别是 k-means , 特征选择策略

### 2018.3.14

1. word2vec 源码，复习word2vec

### 2018.3.13

1. 打印简历，按照简历上的内容复习，主要是项目内容要搞清楚 ==下次写的详细一点==

2. 12 号的任务2，3，4 继续完成

   ​

### 2018.3.12

1. 最终修改简历，投网易，准备今日头条
2. 把逻辑斯蒂回归 的实验完成 ，看随机森林，决策树
2. 看CNN 文本分类 的那篇文章，把文本理解那个实验流程过一遍，特别是 k-means , 特征选择策略
3. 突击看下操作系统，尤其解决操作系统并发性，死锁问题，redis数据库

### 2018.3.11

1. 复习决策树，从ID3，C4.5，到随机森林，实践李宏毅的那个kaggle，从逻辑斯蒂回归，决策树，随机森林实践
2. ==反向传播推导==，==极大似然推导==，==交叉熵==
3. 二叉树题目(主要找剑指offer)
4. 动态规划题目(主要找剑指offer)

### 2018.3.10

1. 复习隐马尔科夫模型，和在Geguio 课上HMM 的应用

### 2018.3.9

1. 开始有必要整理 mooc 的那个项目
2. 逻辑斯蒂回归，最大熵，李宏毅逻辑斯蒂回归作业
3. 隐马尔科夫推导
4. 整理对话系统内容

### 2018.3.8

1. 上午全力复习二叉树算法
2. 机器学习算法
3. 下午修改简历，联系高一鸣
4. 目前算是每天跟进算法，数据结构，但是在机器学习，基础的网络，操作系统，数据库，Linux ，C ++ 语法 知识点上非常有欠缺，希望找今天能快速进行整理种类，大问题化小问题，尽可能在下周面试前过一遍

### 2018.3.7

1. 算法作业 (下午之前完成)
2. 想继续看NN4NLP 上CNN 章节的内容，CNN for modle sentence 
3. 想查一下hashmap 相关的应用，以及并发性题目   (没时间可以不做)
4. 想集中看下二叉树相关题目
5. 其实想花一些时间总结下 “机器翻译” 课上内容 （尽量抽时间做）

### 2018.3.6

1. 上午 ： Leetcode 实战 [String to Integer (atoi)](https://leetcode.com/problems/string-to-integer-atoi)   [Merge Two Sorted Lists](https://leetcode.com/problems/merge-two-sorted-lists)    

2. 希望从深度学习项目中抽出一个机器算法开始学习，复习

   目前确定的是CNN ，因为之前有CNN 的基础

   仔细阅读 

   Convolutional Neural Network Architectures for Matching Natural Language Sentences

   学习CNN

3. 想查一下hashmap 相关的应用，以及并发性题目，整理

4. 剑指offer 3.3



### 2018.3.5

1. 上午实战，1小时 两道题

   [Longest Common Prefix](https://leetcode.com/problems/longest-common-prefix)    

   [Longest Palindromic Substring](https://leetcode.com/problems/longest-palindromic-substring)   

2. 整理深度文本匹配项目描述

3. 朴素贝叶斯及应用,==多分类器的学习，AdaBoost==

   > 这里Boost 只是告诉自己这里是实践中的重点

   ==希望结合自己的简历来整理一套思路来==

4. RNN 知识，这一块必须实践！！！！

   > 深度学习这一块‘

5. 剑指offer 3.3 章节16~19 

补充：

1. 今天算法做了一些和字符串相关的题目，总结下字符串的使用
2. 整理算法课上的 "分治法“

### 2018.3.4

计划：

1. 2.4 算法章节==必须刷完==

   早上时间，要解决2.4.1~2.4.2

   下午时间，尽量解决完成

2. leetcode 实战 2题

3. 再刷完这一部分，我希望能从项目出发，找到一个机器学习算法，结合 “对话系统”，深入研究

   读读论文    LEARNING END-TO-END GOAL-ORIENTED DIALOG

### 2018.3.2

回顾昨天的计划没有完成：

原因：

1. 课程比较多
2. 时间抓的不紧
3. c++ 基础遗忘

#### 计划

1. 2.3.4 2.3.5 刷完
2. 可以再找leetcode 中题目练习
3. 深度文本匹配任务的LSTM 项目推进  (整理之前的思路先，同时可以看看rnn 的知识)

###2018.3.1

近期重要目标==清理完《剑指offer》==

本周 到本周日  周四，周五，周六，周日

1. 最低刷完剑指offer第2章

   2.3 数据结构

   2.4 算法和数据结构

2. 完成CNN for model sentence ，以及 RNN ， LSTM 基础学习

   ==主要是关注项目方面能够自圆其说,希望能更多的侧重深度学习==

3. 完善自己的简历

3.1 :

1. 剑指offer 2.3.1，2.3.2，2.3.3
2. 之前翻译课上没看完的论文继续看，有所整理，可以的话，尽量看下RNN,这里要看机器翻译最新的论文

Neural Machine Translation by Jointly Learning to Align and Translate



### 2018.1.30

现在回家啦

想看看这个 Magnet 桌面分屏软件

###2018.1.26

1. 回家之前对机器学习完全的重新学习，学习深度学习的同时，复习整理之前的机器学习内容
   - 主要结合“李宏毅” 机器学习视频
   - andrew 机器学习和深度学习视频
   - 实践方面主要集中在短文本匹配
     - 学习深度学习 CNN，RNN，LSTM 基础知识
     - ​
2. 算法，今天确定一门算法课程，可以使普林斯顿大学的算法课程，or something beautiful

###2018.1.24

1. 使用TensorFlow 和keras 分别实现CNN

   以前对CNN 很感兴趣，那么放手去做吧

==The main thing is to **start**!==

==Don't spend *too* much time deciding where to start: **start** asap!==

###2018.1.9

### 2018.1.8

### 2018.1.7(考试)

### 2018.1.6

### 2018.1.5

### 2018.1.4

1. 解决最基础贝叶斯网
2. 人工神经网，也可以看看 cousera 上的BP
3. A* 算法彻底解决
4. 聚类，这个必须抓紧

### 2018.1.3

1. 贝叶斯网章节，从朴素贝叶斯，到贝叶斯网
2. 知识表示，也就是第一题会做
3. 机器学习:人工神经网章节，

### 2018.1.2

1. 机器学习考点整理，大致的复习思路,决策树加示例学习\
2. 数据挖掘性能测试报告最终完成
3. 人工智能实验报告，贝叶斯网暂放
4. 分配大概1 小时看ASAG/kaggle

### 2018.1.1

> 新的一年需要执行力

1. 数据挖掘实验报告搞定，下午写好实验报告框架，晚上写shell 脚本进行多因素的性能测试 ==搞定一半==

2. 人工智能实验报告搞定 ==Delay==

3. 继续看贝叶斯，贝叶斯网，做一题贝叶斯网的习题14.12(进而解决人工智能习题)

   http://www.52nlp.cn/prml%E8%AF%BB%E4%B9%A6%E4%BC%9A%E7%AC%AC%E5%85%AB%E7%AB%A0-graphical-models#more-7603

### 2017.12.31

1. FP-growth,加实验报告 $\color{red}{Fail}$
2. 先看机器学习的贝叶斯(看考不考)，再看人工智能的贝叶斯网

### 2017.12.30

1. 博弈搜索，加题目    $\color{red}{Success}$

2. 贝叶斯，贝叶斯网

3. 搜索实验报告

   ​

###2017.12.29

下午：

两个小时

1. 搞定人工智能作业，博弈搜索一道题
2. a*解决八数码搜索实验
3. 查找下一个实验的资料

晚上：



### 2017.12.28

插入自然语言处理的HMM

人工智能的A* 解决八数码问题

### 2017.12.27

最理想的期望吧，还是在学习的同时能深入的实践学习到的知识，无论是人工智能的搜索，还是机器学习中的各种算法，能实践最为主要的算法就好

| Task                 | type    | Priority | Delay Reson          | Expect Time Cost (all:7) | True Time Cost |
| -------------------- | ------- | -------- | -------------------- | ------------------------ | -------------- |
| 局部搜索，博弈搜索，约束满足       | In plan | 高        |                      | 1.5 hour                 |                |
| 做A*，博弈树的题，各至少一道      | in plan | 高        |                      | 1 hour                   |                |
| ID3决策树代码阅读           | in plan | 中        |                      | 1 hour                   |                |
| 修改ID3决策树代码是实现C4.5，剪枝 | in plan | 中        | $\color{red}{Delay}$ | 2 hour                   |                |
| 充能                   | in plan | 高        |                      | 1.5 hour                 |                |
| OJ 清完 昨天的那个+一个easy   | in plan | 中        |                      | 1 hour                   |                |

### 2017.12.26

- [x] 人工智能作业先搞定，顺便也算复习了，主要是搜索算法那个章节
- [ ] 决策树在人家的代码基础上实现C 4.5 和剪枝，比较正确率，还有那个代码并没有剪枝，

小日记：

发现自己对时间的估计很有问题，根本就不能很好的估计时间，抓不住时间，我想更多的有可能是没有课外的事情能体会到乐趣吧

做了什么

1. 完成了一个半的OJ 题，第一个一次accept ,第二个正在采取tries 树的方式，第二个没做完也要总结下原因的
2. 看了人工智能搜索哪一章节，主要是问题的形式化，无信息搜索，启发式搜索
3. 习题完成了两道

| Task                                     | type     | Priority | Delay Reson   | Expect Time Cost (all:7) | True Time Cost |
| ---------------------------------------- | -------- | -------- | ------------- | ------------------------ | -------------- |
| 复习搜索技术(上) <br />搜索问题定义<br />无信息搜索<br />启发式搜索 | In plan  | 高        | Successed     | 2 hour                   | 没有估计           |
| 搜索相关习题两道                                 | in plan  | 高        | Successed     | 1 hour                   | 没有估计           |
| ID3决策树代码阅读                               | in plan  | 中        | delay,插入OJ    | 1 hour                   | 0              |
| 修改ID3决策树代码是实现C4.5，剪枝                     | in plan  | 中        | delay，上午插入了OJ | 2 hour                   | 0              |
| 充能（看了晚会）                                 | in plan  | 高        | 时间过长          | 1.5 hour                 | 3 hour         |
| OJ 两道 + tries 树 算法(continue)             | out plan |          |               | 1 hour                   | 2 hour         |

1 小时 “**充能**”：

干了啥? 

### 2017.12.25

- [ ] 决策树总结，baseline 搞定
- [ ] 人工智能作业先搞定，顺便也算复习了，主要是搜索算法那个章节
- [ ] 制定 人工智能，机器学习，数据挖掘考试复习规划

### 2017.12.20

- [x] 数据挖掘作业4~7
- [ ] Neubig 依存分析，晚上做完作业
- [ ] 解决之前baseline 的疑问，用sklearn 重写
- [ ] 看Deep learning match sentence

> 趁师兄在多问问

### 2017.12.19

- [x] 数据挖掘作业1~3
- [ ] Neubig 依存分析，晚上做完作业 ==loss==
- [ ] 解决之前baseline 的疑问 ==loss==

### 2017.12.18

- [ ] Neubig 的依存分析
- [x] 把baseline 跑出来,大概看下结果,想学习依存分析和决策树
- [ ] 数据挖掘作业1~4

### 2017.12.16

- [ ] 研读 [SemEval 2013](https://www.cs.york.ac.uk/semeval-2013/index.html) 中的Task 7,给出对ASAG 的一个较为全面的总结
- [ ] 跑起来SemEval 的baseLine,看那篇baseline 的文章,尝试读代码,跑起来实验,这个任务,可以分为**2**天工作量
- [ ] 卷积神经网ppt 学习,晚上开始实践 

### 2017.12.15

- [x] ASAG 调研     *The Eras and Trends of Automatic Short Answer Grading*

      一直在完成这部分,了解到一个这个课题的评测,相当于打开新世界的大门吧,大致了解到这个领域其实包含了非常多的内容,技术覆盖到nlp 的方方面面,感觉非常适合入门nlp

- [ ] 卷积神经网ppt 学习,晚上开始实践      ==loss==

- [ ] 文本相似度实现方案 ==loss==

- [ ] 编程练习: **卷积神经网**  ==loss==

###2017.12.12

1. 信息检索相关内容学习,总结出与自己课题相关的内容
2. 深度学习技术学习
3. 课程学习  

###2017.12.10

1. NN4NLP,7 Neural Encoder-Decoder Models
2. *NEURAL MACHINE TRANSLATION  BY JOINTLY LEARNING TO ALIGN AND TRANSLATE*




### 编程任务

1. leetcode

   in python and c++

2. CNN for model sentence 练习

3. SemEval 2013 baseline 复现

   ​



###TODO 准则

1. **每天应该干什么应该在这一天之前制定**

   > 这个太需要强调了，不要把宝贵的要实践的时间浪费在犹豫要干什么上！！！

2. 一周应该有个总体的内容

3. 每天应该有个完成情况的反馈

4. 每天必须有编程任务

5. 在对任务进行规划的时候一定不要贪多量,否则很难完成,没有成就感

6. 任务完成情况，如果做了其他工作，也可以写在这里，也要写delay 的原因

7. 对自己的TODO 保持足够的尊重，就像尊重生命一样

8. TO DO 可能不需要写的那么精致，10 mins 搞定是最好的

9. 机会只会给有准备的人，因此时刻知道自己要什么
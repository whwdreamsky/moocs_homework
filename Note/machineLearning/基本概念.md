# 特征选择

> 这里是总结在有非常多特征下怎么寻找最重要特征



### 模型选择

- 正则化，也就是加入惩罚项，思想是优先选择复杂度比较低的模型，选择经验风险和模型复杂度同时较小的
  - L1 范数 : 求和 参数项
  - L2 范数：求和 参数 平方项，主要用于防止过拟合
- 交叉验证：留出发，k-折交叉验证
- 模型分类：生成式方法，判别式方法
  - 生成式方法：由数据学习联合概率分布P(X,Y), 根据贝叶法则，求出条件分布

    如：朴素贝叶斯，

  - 判别式方法：直接由数据学习条件概率分布P(Y|X) ,关心的是给定什么X 预测什么Y 

  ​

### 自然语言处理中常见的特征抽取



### 特征相关性判断

在“机器学习课上” 有对数据进行 std 处理，这个操作是归一标准差



the standard deviation of the corresponding parameter in the data
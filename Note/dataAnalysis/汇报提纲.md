#2017 秋季学期期末总结

[TOC]

###Mooc讨论区文本分析

####问题定义

之前的定义：与以往的Ｍooc数据分析通过点击,观看视频时长等用户操作不同,本课题针对慕课中 `讨论区问题的回复` 进行文本分析,根据问题的回复判断学生对问题的理解情况,最终实现对该问题所有学生的理解情况进行打分

Semval13 的**THE STUDENT RESPONSE ANALYSIS TASK**任务：给出一个问题，多个已知的参考答案，一个学生回答，目标是为学生回答打分

####ASAG（自动短回答评分）

![](/Users/oliver/Desktop/AI_photo/asag/asag.1.png)

#### 数据集

使用 Dzikovska et al., 2010 提供的BEETLE II data 数据集2729 条数据

#### 评价标准

有三种打分方式，5-way,2-way,3-way，分别是不同粒度的划分，同时难度也随之递减

- 5-way:

  回答主要评价为5类，正确(correct),部分正确(partially_correct_incomplete)，不切题(irrelevant)，不在范围内(non_domain)，矛盾(contradictory)

- 3-way:

  正确(correct) , 矛盾(contradictory),不正确 (incorrect)

- 2-way:

  正确 (correct),不正确 (incorrect)

~~~python
# question: Explain why you got a voltage reading of 1.5 for terminal 1 and the positive terminal
# reference:Terminal 1 and the positive terminal are separated by the gap
# reference2:Terminal 1 and the positive terminal are not connected
# student answer:
# correct:Because there was a gap between the positive battery terminal and terminal 1
# contradictory: There was a connection between terminal 1 and the positive terminal
# irrelevant:Voltage is the difference between a positive and negative end on a batter    y
# non_domain : i do not understand
~~~

数据类别的分布如下图

| type                         | number | Freq |
| ---------------------------- | ------ | ---- |
| Correct                      | 1157   | 0.42 |
| partially_correct_incomplete | 626    | 0.23 |
| irrelevant                   | 656    | 0.24 |
| non_domain                   | 86     | 0.03 |
| contradictory                | 204    | 0.07 |

#### baseline

本次实现选择，问题和学生回答，标准答案和学生回答的相似度指标作为特征，根据来自 perl 的Text::Similarity::Overlaps module 包，选择overlap，cosine ，F1 score，Lesk 四个相似度指标，抽取特征后使用C4.5 分类器分类。

1. overlap_SR_RR ：这里取学生回答和标准回答的词重叠的最大值
2. overlap_SR_QE ：这里取学生回答和问题的词重叠
3. cosine_SR_RR:  这里取学生回答和标准回答的词袋cosine的最大值
4. cosine_SR_QE：这里取学生回答和问题的cosine值
5. F1 score_SR_RR：这里取学生回答和标准回答的F1的最大值
6. F1 score_SR_QE：这里取学生回答和问题的F1
7. Lesk score_SR_RR：这里取学生回答和标准回答的 Lesk score的最大值
8. Lesk score_SR_QE：这里取学生回答和问题的F1

#### 实验结果

| fold | precision_macro | recall_macro | f1_macro    |
| ---- | --------------- | ------------ | ----------- |
| 1    | 0.4276555       | 0.50137522   | 0.44957526  |
| 2    | 0.38705993      | 0.43746493   | 0.4006479   |
| 3    | 0.3997114       | 0.43505314   | 0.40890503  |
| 4    | 0.41046657      | 0.37671502   | 0.38927187  |
| 5    | 0.36270728      | 0.3913147    | 0.37303859  |
| 6    | 0.32859919      | 0.37978747   | 0.34863447  |
| 7    | 0.39719891      | 0.41372596   | 0. 40068495 |
| 8    | 0.42081027      | 0. 42062816  | 0. 42050085 |
| 9    | 0.36802488      | 0. 43862554  | 0. 38782814 |
| 10   | 0.38735816      | 0. 45647268  | 0. 41280159 |
| mean | 0.38895920      | 0.425116281  | 0.39918886  |

| way   | precision_macro     | recall_macro        | f1_macro            |
| ----- | ------------------- | ------------------- | ------------------- |
| 2-way | 0.64531083586420279 | 0.64173851348301125 | 0.64076027952262393 |
| 3-way | 0.45058391048394669 | 0.44906114043674294 | 0.44723338921101491 |
| 5-way | 0.38895920          | 0.425116281         | 0.39918886          |

####实现流程

![](/Users/oliver/Desktop/AI_photo/2017期末检查/流程mooc1.png)



####MatchZoo 深度文本匹配工具箱

matchzoo 是一个深度文本匹配的一个工具箱，它实现了现在最新的10个深度文本匹配模型，它能应用在转述，文本蕴含，问答，对话，信息检索上。

| Tasks                      | Text 1   | Text 2     | Objective              |
| -------------------------- | -------- | ---------- | ---------------------- |
| Paraphrase Indentification | string 1 | string 2   | classification         |
| Textual Entailment         | text     | hypothesis | classification         |
| Question Answer            | question | answer     | classification/ranking |
| Conversation               | dialog   | response   | classification/ranking |
| Information Retrieval      | query    | document   | ranking                |

### 学习内容

- 公开课
  - **Graham Neubig's Teaching**
    - [Programming Basics](http://www.phontron.com/slides/nlp-programming-en-00-intro.pdf)
    - [Unigram Language Models](http://www.phontron.com/slides/nlp-programming-en-01-unigramlm.pdf)
    -  [Bigram Language Models](http://www.phontron.com/slides/nlp-programming-en-02-bigramlm.pdf)
    -  [Word Segmentation](http://www.phontron.com/slides/nlp-programming-en-03-ws.pdf)
    - [Part-of-Speech Tagging with Hidden Markov Models](http://www.phontron.com/slides/nlp-programming-en-04-hmm.pdf)
    - [The Perceptron Algorithm](http://www.phontron.com/slides/nlp-programming-en-05-perceptron.pdf)
    - [Advanced Discriminative Training](http://www.phontron.com/slides/nlp-programming-en-06-discriminative.pdf)
    - [Neural Networks](http://www.phontron.com/slides/nlp-programming-en-07-nn.pdf)
  - **Neural Networks for Nlp**
    - Predicting the Next Word in a Sentence
    - Models of Words:word2vec
    - Models of Sentences:CNN
- 课程学习
  - 机器学习
  - 数据挖掘
  - 自然语言处理
  - 人工智能
  - 组合数学
- TeaEvening ： 做了神经网络模型，词向量word2vec，层次softmax加速的分享

### 未来规划

- 比较关注短文本的语义理解，希望能结合论文把MatchZoo 的模型的实现理解清楚
- 在MatchZoo 提供的模型的基础上，对ASAG 任务进行自己的优化，例如他都是给定两个串比较相似度，如何参照问题和参考答案两方面构建模型

